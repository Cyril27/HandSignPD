{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11371457,"sourceType":"datasetVersion","datasetId":7118773},{"sourceId":11651117,"sourceType":"datasetVersion","datasetId":7311705}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import libraries and load raw NewHandPD Dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport pandas as pd\nfrom collections import defaultdict\nfrom itertools import product\nimport random\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms.functional as TF\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torchvision.transforms import ColorJitter\nimport torch.optim as optim\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-02T18:59:29.798510Z","iopub.execute_input":"2025-05-02T18:59:29.799239Z","iopub.status.idle":"2025-05-02T18:59:38.931033Z","shell.execute_reply.started":"2025-05-02T18:59:29.799212Z","shell.execute_reply":"2025-05-02T18:59:38.930190Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Data pre-processing\n### Get patient metadata from Signals files","metadata":{}},{"cell_type":"code","source":"def get_patient_data(folder_path, _type):\n    if _type == 'healthy':\n        filename_pattern = re.compile(r'^sigMea3-H(\\d+)\\.txt$')\n    elif _type == 'parkinson':\n        filename_pattern = re.compile(r'^sigMea3-P(\\d+)\\.txt$') \n        \n    fields = ['Gender', 'Writing_Hand', 'Weight', 'Height', 'Smoker']\n    \n    defaults = {\n        'Gender': -1,\n        'Writing_Hand': -1,\n        'Weight': -1,\n        'Height': -1,\n        'Smoker': -1\n    }\n    \n    data = []\n    for filename in os.listdir(folder_path):\n        match = filename_pattern.match(filename)\n        if not match:\n            continue\n    \n        number = int(match.group(1))\n        file_path = os.path.join(folder_path, filename)\n    \n        metadata = defaults.copy()\n        with open(file_path, 'r') as f:\n            for line in f:\n                for field in fields:\n                    if f\"<{field}>\" in line:\n                        value = re.search(rf\"<{field}>(.*?)</{field}>\", line)\n                        if value and value.group(1).isdigit():\n                            metadata[field] = int(value.group(1))\n\n        if _type == 'healthy':\n            row = ['H' + str(number)] + [metadata[k] for k in fields]\n        elif _type == 'parkinson':\n            row = ['P' + str(number)] + [metadata[k] for k in fields]\n        data.append(row)\n\n    # one-hot encoding of categorical variables\n    df = pd.DataFrame(data, columns=['Number'] + fields)\n    df = pd.get_dummies(df, columns=['Gender', 'Writing_Hand', 'Smoker'], drop_first=True)\n    df = df.applymap(lambda x: 1 if x is True else (0 if x is False else x))\n    \n    df['SortKey'] = df['Number'].str.extract(r'([0-9]+)').astype(int)\n    df = df.sort_values('SortKey').drop(columns='SortKey').reset_index(drop=True)\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T18:59:47.511117Z","iopub.execute_input":"2025-05-02T18:59:47.511626Z","iopub.status.idle":"2025-05-02T18:59:47.521876Z","shell.execute_reply.started":"2025-05-02T18:59:47.511600Z","shell.execute_reply":"2025-05-02T18:59:47.521083Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"healthy_df = get_patient_data('/kaggle/input/patient/Signal', 'healthy')\nparkinson_df = get_patient_data('/kaggle/input/patient/Signal 2', 'parkinson')\n\nprint(len(healthy_df))\nprint(len(parkinson_df))\n\nhealthy_df = healthy_df[~(healthy_df == -1).any(axis=1)].reset_index(drop=True)\nparkinson_df = parkinson_df[~(parkinson_df == -1).any(axis=1)].reset_index(drop=True)\nparkinson_df['Smoker_2'] = 0\n\nprint(len(healthy_df))\nprint(len(parkinson_df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T18:59:50.981344Z","iopub.execute_input":"2025-05-02T18:59:50.981927Z","iopub.status.idle":"2025-05-02T18:59:53.133361Z","shell.execute_reply.started":"2025-05-02T18:59:50.981902Z","shell.execute_reply":"2025-05-02T18:59:53.132530Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2780708925.py:43: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n  df = df.applymap(lambda x: 1 if x is True else (0 if x is False else x))\n","output_type":"stream"},{"name":"stdout","text":"35\n31\n30\n31\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/2780708925.py:43: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n  df = df.applymap(lambda x: 1 if x is True else (0 if x is False else x))\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Numerical variables normalization after concatenation of healthy and PD metadata\ndata_df = pd.concat([healthy_df, parkinson_df], ignore_index=True)\ndata_df['Weight'] = (data_df['Weight'] - data_df['Weight'].min()) / (data_df['Weight'].max() - data_df['Weight'].min())\ndata_df['Height'] = (data_df['Height'] - data_df['Height'].min()) / (data_df['Height'].max() - data_df['Height'].min())\n\nprint(len(data_df))\nprint(data_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T18:59:55.542736Z","iopub.execute_input":"2025-05-02T18:59:55.543293Z","iopub.status.idle":"2025-05-02T18:59:55.559037Z","shell.execute_reply.started":"2025-05-02T18:59:55.543266Z","shell.execute_reply":"2025-05-02T18:59:55.558252Z"}},"outputs":[{"name":"stdout","text":"61\n   Number    Weight    Height  Gender_2  Writing_Hand_2  Smoker_2\n0      H1  0.578125  0.764706         0               0         0\n1      H2  0.437500  1.000000         0               0         0\n2      H3  0.421875  0.176471         1               0         0\n3      H4  0.812500  0.676471         0               0         0\n4      H5  0.312500  0.294118         0               0         1\n..    ...       ...       ...       ...             ...       ...\n56    P28  0.234375  0.147059         1               0         0\n57    P29  0.687500  0.441176         1               0         0\n58    P30  0.328125  0.441176         0               0         0\n59    P31  0.437500  0.294118         1               0         0\n60    P32  0.531250  0.588235         0               0         0\n\n[61 rows x 6 columns]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### Image pairs formation, matching with metadata and splitting in training, validation, test datasets ","metadata":{}},{"cell_type":"code","source":"dataset_path = '/kaggle/input/newhandpd'\n\ndef extract_ids(filename):\n    base = os.path.splitext(filename)[0]  \n    parts = base.split('-')\n    if len(parts) == 2:\n        return parts[0], parts[1] \n    return None, None\n\ndef get_pairs_by_person(group_prefix):\n    spiral_path = os.path.join(dataset_path, f\"{group_prefix}Spiral\")\n    meander_path = os.path.join(dataset_path, f\"{group_prefix}Meander\")\n\n    spiral_dict = defaultdict(list)\n    meander_dict = defaultdict(list)\n\n    for fname in os.listdir(spiral_path):\n        _, person_id = extract_ids(fname)\n        if person_id:\n            spiral_dict[person_id].append(os.path.join(f\"{group_prefix}Spiral\", fname))\n\n    for fname in os.listdir(meander_path):\n        _, person_id = extract_ids(fname)\n        if person_id:\n            meander_dict[person_id].append(os.path.join(f\"{group_prefix}Meander\", fname))\n\n    # Group all pairs per person\n    person_to_pairs = defaultdict(list)\n    for person_id in spiral_dict:\n        if person_id in meander_dict:\n            pairs = list(product(spiral_dict[person_id], meander_dict[person_id]))\n            person_to_pairs[person_id].extend(pairs)\n\n    return person_to_pairs\n\n\ndef enrich_and_filter_pairs(person_to_pairs, df):\n    enriched = {}\n    valid_ids = set(df['Number'])\n\n    for person_id, pairs in person_to_pairs.items():\n        if person_id in valid_ids:\n            row = df[df['Number'] == person_id].iloc[0].to_dict()\n            enriched[person_id] = {\n                'pairs': pairs,\n                'metadata': row\n            }\n    return enriched\n\ndef split_by_individuals(person_to_data, seed=42):\n    person_ids = list(person_to_data.keys())\n    random.seed(seed)\n    random.shuffle(person_ids)\n\n    total = len(person_ids)\n    n_train = int(0.7 * total)\n    n_val = int(0.15 * total)\n\n    train_ids = person_ids[:n_train]\n    val_ids = person_ids[n_train:n_train + n_val]\n    test_ids = person_ids[n_train + n_val:]\n\n    train_pairs = [(pair, dict(list(person_to_data[pid]['metadata'].items())[1:])) \n               for pid in train_ids for pair in person_to_data[pid]['pairs']]\n\n    val_pairs = [(pair, dict(list(person_to_data[pid]['metadata'].items())[1:])) \n                 for pid in val_ids for pair in person_to_data[pid]['pairs']]\n    \n    test_pairs = [(pair, dict(list(person_to_data[pid]['metadata'].items())[1:])) \n                  for pid in test_ids for pair in person_to_data[pid]['pairs']]\n\n\n    return train_pairs, val_pairs, test_pairs\n\n\nhealthy_pairs_by_person = get_pairs_by_person(\"Healthy\")\npatient_pairs_by_person = get_pairs_by_person(\"Patient\")\n    \nhealthy_data = enrich_and_filter_pairs(healthy_pairs_by_person, data_df)\nparkinson_data = enrich_and_filter_pairs(patient_pairs_by_person, data_df)\n\nhealthy_train, healthy_val, healthy_test = split_by_individuals(healthy_data)\npatient_train, patient_val, patient_test = split_by_individuals(parkinson_data)\n\n\nprint(\"Healthy:\")\nprint(f\"  Train: {len(healthy_train)} pairs\")\nprint(f\"  Val:   {len(healthy_val)} pairs\")\nprint(f\"  Test:  {len(healthy_test)} pairs\")\n\nprint(\"\\nPatient:\")\nprint(f\"  Train: {len(patient_train)} pairs\")\nprint(f\"  Val:   {len(patient_val)} pairs\")\nprint(f\"  Test:  {len(patient_test)} pairs\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T18:59:58.549536Z","iopub.execute_input":"2025-05-02T18:59:58.550334Z","iopub.status.idle":"2025-05-02T18:59:58.629951Z","shell.execute_reply.started":"2025-05-02T18:59:58.550308Z","shell.execute_reply":"2025-05-02T18:59:58.629048Z"}},"outputs":[{"name":"stdout","text":"Healthy:\n  Train: 336 pairs\n  Val:   64 pairs\n  Test:  80 pairs\n\nPatient:\n  Train: 336 pairs\n  Val:   64 pairs\n  Test:  96 pairs\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### Dataset building for original image pairs and for contrast augmentation (adapted to include images pairs and metadata)","metadata":{}},{"cell_type":"code","source":"class Dataset_no_data_aug(Dataset):\n    def __init__(self, pairs, root_dir, label, img_size=(128, 128)):\n        self.pairs = pairs  \n        self.root_dir = root_dir\n        self.label = label  \n        self.img_size = img_size\n\n        self.metadata_keys = ['Weight', 'Height', 'Gender_2', 'Writing_Hand_2', 'Smoker_2']\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        (spiral_path, meander_path), metadata = self.pairs[idx]\n\n        spiral_img = Image.open(os.path.join(self.root_dir, spiral_path)).convert(\"RGB\")\n        meander_img = Image.open(os.path.join(self.root_dir, meander_path)).convert(\"RGB\")\n\n        # Resize to 128x128 dimensions\n        spiral_img = TF.resize(spiral_img, self.img_size)\n        meander_img = TF.resize(meander_img, self.img_size)\n\n        # Save in tensor\n        spiral_img = TF.to_tensor(spiral_img)\n        meander_img = TF.to_tensor(meander_img)\n\n        # Normalization\n        mean = [0.485, 0.456, 0.406]  \n        std = [0.229, 0.224, 0.225]  \n        spiral_img = TF.normalize(spiral_img, mean, std)\n        meander_img = TF.normalize(meander_img, mean, std)\n\n        meta_tensor = torch.tensor([metadata[k] for k in self.metadata_keys], dtype=torch.float)\n\n        y = torch.tensor(self.label, dtype=torch.long)\n        \n        return spiral_img, meander_img, meta_tensor, y\n\n\nclass Dataset_contrast(Dataset):\n    def __init__(self, pairs, root_dir, label, img_size=(128, 128), contrast_factor_range=(0.5, 1.5)):\n        self.root_dir = root_dir\n        self.label = label\n        self.img_size = img_size\n        self.contrast_factor_range = contrast_factor_range\n\n        self.expanded_pairs = [((pair, metadata), False) for pair, metadata in pairs] + \\\n                              [((pair, metadata), True) for pair, metadata in pairs]\n\n        self.metadata_keys = ['Weight', 'Height', 'Gender_2', 'Writing_Hand_2', 'Smoker_2']\n\n    def __len__(self):\n        return len(self.expanded_pairs)\n\n    def __getitem__(self, idx):\n        ((spiral_path, meander_path), metadata), apply_contrast = self.expanded_pairs[idx]\n\n        spiral_img = Image.open(os.path.join(self.root_dir, spiral_path)).convert(\"RGB\")\n        meander_img = Image.open(os.path.join(self.root_dir, meander_path)).convert(\"RGB\")\n\n        spiral_img = TF.resize(spiral_img, self.img_size)\n        meander_img = TF.resize(meander_img, self.img_size)\n\n        # Apply contrast augmentation\n        if apply_contrast:\n            contrast_factor = random.uniform(*self.contrast_factor_range)\n            spiral_img = TF.adjust_contrast(spiral_img, contrast_factor)\n            meander_img = TF.adjust_contrast(meander_img, contrast_factor)\n\n        spiral_img = TF.to_tensor(spiral_img)\n        meander_img = TF.to_tensor(meander_img)\n\n        mean = [0.485, 0.456, 0.406]\n        std = [0.229, 0.224, 0.225]\n        spiral_img = TF.normalize(spiral_img, mean, std)\n        meander_img = TF.normalize(meander_img, mean, std)\n\n        meta_tensor = torch.tensor([metadata[k] for k in self.metadata_keys], dtype=torch.float)\n        y = torch.tensor(self.label, dtype=torch.long)\n\n        return spiral_img, meander_img, meta_tensor, y\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:00:02.705141Z","iopub.execute_input":"2025-05-02T19:00:02.705426Z","iopub.status.idle":"2025-05-02T19:00:02.718824Z","shell.execute_reply.started":"2025-05-02T19:00:02.705402Z","shell.execute_reply":"2025-05-02T19:00:02.717965Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### Combine healthy and PD labeled image pair datasets","metadata":{}},{"cell_type":"code","source":"def create_dataset_no_data_aug(pairs_healthy, pairs_patient, root_dir, img_size=(128, 128)):\n    dataset = (\n        Dataset_no_data_aug(pairs_healthy, root_dir=root_dir, label=0,\n                          img_size=img_size) +\n        Dataset_no_data_aug(pairs_patient, root_dir=root_dir, label=1,\n                          img_size=img_size)\n    )\n    return dataset\n\ndef create_dataset_contrast(pairs_healthy, pairs_patient, root_dir, img_size=(128, 128)):\n    dataset = (\n        Dataset_contrast(pairs_healthy, root_dir=root_dir, label=0,\n                          img_size=img_size) +\n        Dataset_contrast(pairs_patient, root_dir=root_dir, label=1,\n                          img_size=img_size)\n    )\n    return dataset\n\n\ntrain_dataset = create_dataset_no_data_aug(healthy_train, patient_train, dataset_path, img_size=(128,128))\nval_dataset   = create_dataset_no_data_aug(healthy_val, patient_val, dataset_path, img_size=(128,128))\ntest_dataset  = create_dataset_no_data_aug(healthy_test, patient_test, dataset_path, img_size=(128,128))\n\ntrain_dataset_contrast = create_dataset_contrast(healthy_train, patient_train, dataset_path, img_size=(128,128))\n\nprint(len(train_dataset))\nprint(len(val_dataset))\nprint(len(test_dataset))\n\nprint(len(train_dataset_contrast))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:00:06.725431Z","iopub.execute_input":"2025-05-02T19:00:06.726159Z","iopub.status.idle":"2025-05-02T19:00:06.733596Z","shell.execute_reply.started":"2025-05-02T19:00:06.726136Z","shell.execute_reply":"2025-05-02T19:00:06.732872Z"}},"outputs":[{"name":"stdout","text":"672\n128\n176\n1344\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\ntrain_loader_contrast = DataLoader(train_dataset_contrast, batch_size=32, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:00:10.532199Z","iopub.execute_input":"2025-05-02T19:00:10.532887Z","iopub.status.idle":"2025-05-02T19:00:10.537515Z","shell.execute_reply.started":"2025-05-02T19:00:10.532862Z","shell.execute_reply":"2025-05-02T19:00:10.536702Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Definition of the intermediate fusion multimodal model adapted for metadata modality","metadata":{}},{"cell_type":"code","source":"class Intermediate_metadata(nn.Module):\n    def __init__(self, num_classes=2, metadata_dim=5):  \n        super(Intermediate_metadata, self).__init__()\n\n        # Load pretrained ResNet18s\n        base_spiral = models.resnet18(pretrained=True)\n        base_meander = models.resnet18(pretrained=True)\n        base_shared = models.resnet18(pretrained=True)\n\n        # Separate early layers up to layer3\n        self.spiral_early = nn.Sequential(\n            base_spiral.conv1,\n            base_spiral.bn1,\n            base_spiral.relu,\n            base_spiral.maxpool,\n            base_spiral.layer1,\n            base_spiral.layer2,\n            base_spiral.layer3\n        )\n\n        self.meander_early = nn.Sequential(\n            base_meander.conv1,\n            base_meander.bn1,\n            base_meander.relu,\n            base_meander.maxpool,\n            base_meander.layer1,\n            base_meander.layer2,\n            base_meander.layer3\n        )\n\n        self.reduce_spiral = nn.Linear(256, 128)\n        self.reduce_meander = nn.Linear(256, 128)\n\n        # Late resnet18 after fusion\n        self.shared_late = nn.Sequential(\n            base_shared.layer4,\n            base_shared.avgpool\n        )\n\n        # Metadata MLP\n        self.meta_mlp = nn.Sequential(\n            nn.Linear(metadata_dim, 32),\n            nn.ReLU(),\n            nn.Linear(32, 32),\n            nn.ReLU()\n        )\n\n        # Classifier\n        self.classifier = nn.Sequential(\n            nn.Flatten(),  \n            nn.Linear(512 + 32, 128),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, spiral_img, meander_img, metadata):\n\n        # Early feature extraction\n        spiral_feat = self.spiral_early(spiral_img)\n        meander_feat = self.meander_early(meander_img)\n\n        # Global Average Pooling\n        spiral_feat = torch.nn.functional.adaptive_avg_pool2d(spiral_feat, (1, 1)).squeeze(-1).squeeze(-1)\n        meander_feat = torch.nn.functional.adaptive_avg_pool2d(meander_feat, (1, 1)).squeeze(-1).squeeze(-1)\n\n        # Dimensionality reduction\n        spiral_feat = self.reduce_spiral(spiral_feat)\n        meander_feat = self.reduce_meander(meander_feat)\n\n        # Intermediate fusion \n        fused_feat = torch.cat((spiral_feat, meander_feat), dim=1)  \n        fused_feat = fused_feat.unsqueeze(-1).unsqueeze(-1) \n\n        # Late ResNet18 layers\n        fused_feat = self.shared_late(fused_feat)           \n        fused_feat = fused_feat.squeeze(-1).squeeze(-1)      \n\n        # Process metadata\n        meta_feat = self.meta_mlp(metadata)  \n\n        # Final fusion\n        combined_feat = torch.cat((fused_feat, meta_feat), dim=1)  \n\n        # Classifier\n        out = self.classifier(combined_feat)\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:00:12.446493Z","iopub.execute_input":"2025-05-02T19:00:12.447236Z","iopub.status.idle":"2025-05-02T19:00:12.456846Z","shell.execute_reply.started":"2025-05-02T19:00:12.447210Z","shell.execute_reply":"2025-05-02T19:00:12.455999Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"print(\"CUDA available:\", torch.cuda.is_available())\nprint(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:00:18.886297Z","iopub.execute_input":"2025-05-02T19:00:18.886566Z","iopub.status.idle":"2025-05-02T19:00:18.998091Z","shell.execute_reply.started":"2025-05-02T19:00:18.886545Z","shell.execute_reply":"2025-05-02T19:00:18.997487Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nDevice name: Tesla T4\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Define training and testing functions","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, val_loader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for spiral_img, meander_img, metadata, labels in val_loader:\n            spiral_img = spiral_img.to(device)\n            meander_img = meander_img.to(device)\n            metadata = metadata.to(device).float()\n            labels = labels.to(device)\n\n            outputs = model(spiral_img, meander_img, metadata)\n\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n    accuracy = correct / total\n    return accuracy\n\n\ndef train_model2(model, train_loader, val_loader, criterion, optimizer, epochs=10, device=None):\n    model.to(device)\n    train_losses = []\n    train_accuracies = []\n    val_accuracies = []\n\n    for epoch in range(epochs):\n        model.train()\n        train_loss, correct, total = 0.0, 0, 0\n\n        for spiral_img, meander_img, metadata, labels in train_loader:\n            spiral_img = spiral_img.to(device)\n            meander_img = meander_img.to(device)\n            metadata = metadata.to(device).float()\n            labels = labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(spiral_img, meander_img, metadata)\n\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item() * labels.size(0)\n            _, predicted = outputs.max(1)\n            correct += predicted.eq(labels).sum().item()\n            total += labels.size(0)\n\n        train_accuracy = correct / total\n        val_accuracy = evaluate_model(model, val_loader, device)\n\n        train_losses.append(train_loss / total)\n        train_accuracies.append(train_accuracy)\n        val_accuracies.append(val_accuracy)\n\n        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {train_loss/total:.4f}, Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n\n    return train_losses, train_accuracies, val_accuracies\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:00:26.928367Z","iopub.execute_input":"2025-05-02T19:00:26.928991Z","iopub.status.idle":"2025-05-02T19:00:26.937493Z","shell.execute_reply.started":"2025-05-02T19:00:26.928967Z","shell.execute_reply":"2025-05-02T19:00:26.936710Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def test_model(model, test_loader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    all_predictions = []\n    all_labels = []\n\n    with torch.no_grad():\n        for spiral_img, meander_img, metadata, labels in test_loader:\n            spiral_img = spiral_img.to(device)\n            meander_img = meander_img.to(device)\n            metadata = metadata.to(device).float()\n            labels = labels.to(device)\n\n            outputs = model(spiral_img, meander_img, metadata)\n            _, predicted = torch.max(outputs, 1)\n\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n            all_predictions.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    accuracy = correct / total\n    print(f\"Test Accuracy: {accuracy:.4f}\")\n    return accuracy, all_predictions, all_labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:00:39.857743Z","iopub.execute_input":"2025-05-02T19:00:39.858024Z","iopub.status.idle":"2025-05-02T19:00:39.864392Z","shell.execute_reply.started":"2025-05-02T19:00:39.858002Z","shell.execute_reply":"2025-05-02T19:00:39.863394Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### training and testing while using hyperpamaters values of models 1 and 2","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_loader = train_loader_contrast\n\nlr = 0.0005\nwd = 0.0\n\nmodel = Intermediate_metadata(num_classes=2).to(device)\n\noptimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\ncriterion = nn.CrossEntropyLoss()\n\ntrain_losses, train_accuracies, val_accuracies = train_model2(model, train_loader, val_loader, criterion, optimizer, epochs=10, device=device)\nacc, _, _ = test_model(model, test_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:06:58.613849Z","iopub.execute_input":"2025-05-02T19:06:58.614569Z","iopub.status.idle":"2025-05-02T19:11:42.505828Z","shell.execute_reply.started":"2025-05-02T19:06:58.614545Z","shell.execute_reply":"2025-05-02T19:11:42.504958Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] - Loss: 0.5020, Train Acc: 0.7619, Val Acc: 0.7188\nEpoch [2/10] - Loss: 0.1900, Train Acc: 0.9561, Val Acc: 0.8125\nEpoch [3/10] - Loss: 0.0758, Train Acc: 0.9866, Val Acc: 0.7891\nEpoch [4/10] - Loss: 0.0398, Train Acc: 0.9963, Val Acc: 0.8281\nEpoch [5/10] - Loss: 0.0267, Train Acc: 0.9963, Val Acc: 0.8203\nEpoch [6/10] - Loss: 0.0262, Train Acc: 0.9970, Val Acc: 0.8203\nEpoch [7/10] - Loss: 0.0161, Train Acc: 0.9985, Val Acc: 0.8359\nEpoch [8/10] - Loss: 0.0129, Train Acc: 0.9985, Val Acc: 0.8438\nEpoch [9/10] - Loss: 0.0203, Train Acc: 0.9948, Val Acc: 0.8047\nEpoch [10/10] - Loss: 0.0073, Train Acc: 1.0000, Val Acc: 0.8203\nTest Accuracy: 0.8864\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_loader = train_loader_contrast\n\nlr = 0.0001\nwd = 0.0001\n\nmodel = Intermediate_metadata(num_classes=2).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\ncriterion = nn.CrossEntropyLoss()\n\ntrain_losses, train_accuracies, val_accuracies = train_model2(model, train_loader, val_loader, criterion, optimizer, epochs=10, device=device)\nacc, _, _ = test_model(model, test_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:13:12.212104Z","iopub.execute_input":"2025-05-02T19:13:12.212614Z","iopub.status.idle":"2025-05-02T19:17:56.210398Z","shell.execute_reply.started":"2025-05-02T19:13:12.212593Z","shell.execute_reply":"2025-05-02T19:17:56.209727Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] - Loss: 0.3363, Train Acc: 0.8631, Val Acc: 0.7500\nEpoch [2/10] - Loss: 0.0371, Train Acc: 0.9963, Val Acc: 0.8047\nEpoch [3/10] - Loss: 0.0160, Train Acc: 0.9978, Val Acc: 0.7500\nEpoch [4/10] - Loss: 0.0177, Train Acc: 0.9948, Val Acc: 0.7500\nEpoch [5/10] - Loss: 0.0199, Train Acc: 0.9948, Val Acc: 0.8750\nEpoch [6/10] - Loss: 0.0041, Train Acc: 1.0000, Val Acc: 0.8750\nEpoch [7/10] - Loss: 0.0021, Train Acc: 1.0000, Val Acc: 0.8750\nEpoch [8/10] - Loss: 0.0020, Train Acc: 1.0000, Val Acc: 0.8516\nEpoch [9/10] - Loss: 0.0014, Train Acc: 1.0000, Val Acc: 0.8203\nEpoch [10/10] - Loss: 0.0023, Train Acc: 0.9993, Val Acc: 0.7969\nTest Accuracy: 0.9091\n","output_type":"stream"}],"execution_count":17}]}